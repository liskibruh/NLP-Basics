{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom keras.preprocessing import sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten, LSTM\nfrom keras.layers import Conv1D, GlobalMaxPooling1D","metadata":{"execution":{"iopub.status.busy":"2023-04-24T05:17:54.135682Z","iopub.execute_input":"2023-04-24T05:17:54.136176Z","iopub.status.idle":"2023-04-24T05:17:54.143480Z","shell.execute_reply.started":"2023-04-24T05:17:54.136140Z","shell.execute_reply":"2023-04-24T05:17:54.142040Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"dataset = pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\ndataset['sentiment'] = dataset['sentiment'].replace({'positive': 1, 'negative': 0})\n# sample only 5000 rows randomly (full dataset leads to memory issues)\ndataset = dataset.sample(n=5000, random_state=42)\ndataset","metadata":{"execution":{"iopub.status.busy":"2023-04-24T05:13:40.174952Z","iopub.execute_input":"2023-04-24T05:13:40.176403Z","iopub.status.idle":"2023-04-24T05:13:42.085785Z","shell.execute_reply.started":"2023-04-24T05:13:40.176357Z","shell.execute_reply":"2023-04-24T05:13:42.084533Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                                  review  sentiment\n33553  I really liked this Summerslam due to the look...          1\n9427   Not many television shows appeal to quite as m...          1\n199    The film quickly gets to a major chase scene w...          0\n12447  Jane Austen would definitely approve of this o...          1\n39489  Expectations were somewhat high for me when I ...          0\n...                                                  ...        ...\n39885  One of eastwood's best movies after he had sep...          1\n17566  My blurred childhood memories have kept the ec...          0\n16062  I love Zombie-Movies and I love amateur-produc...          0\n48445  Chan is in New York and he gets involved with ...          1\n20382  My wife and I both thought this film a watered...          0\n\n[5000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>33553</th>\n      <td>I really liked this Summerslam due to the look...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9427</th>\n      <td>Not many television shows appeal to quite as m...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>The film quickly gets to a major chase scene w...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12447</th>\n      <td>Jane Austen would definitely approve of this o...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>39489</th>\n      <td>Expectations were somewhat high for me when I ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>39885</th>\n      <td>One of eastwood's best movies after he had sep...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17566</th>\n      <td>My blurred childhood memories have kept the ec...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16062</th>\n      <td>I love Zombie-Movies and I love amateur-produc...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>48445</th>\n      <td>Chan is in New York and he gets involved with ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20382</th>\n      <td>My wife and I both thought this film a watered...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5000 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"dataset = dataset.to_numpy()\ndataset[0]","metadata":{"execution":{"iopub.status.busy":"2023-04-24T05:13:51.431462Z","iopub.execute_input":"2023-04-24T05:13:51.432718Z","iopub.status.idle":"2023-04-24T05:13:51.441917Z","shell.execute_reply.started":"2023-04-24T05:13:51.432674Z","shell.execute_reply":"2023-04-24T05:13:51.440447Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"array([\"I really liked this Summerslam due to the look of the arena, the curtains and just the look overall was interesting to me for some reason. Anyways, this could have been one of the best Summerslam's ever if the WWF didn't have Lex Luger in the main event against Yokozuna, now for it's time it was ok to have a huge fat man vs a strong man but I'm glad times have changed. It was a terrible main event just like every match Luger is in is terrible. Other matches on the card were Razor Ramon vs Ted Dibiase, Steiner Brothers vs Heavenly Bodies, Shawn Michaels vs Curt Hening, this was the event where Shawn named his big monster of a body guard Diesel, IRS vs 1-2-3 Kid, Bret Hart first takes on Doink then takes on Jerry Lawler and stuff with the Harts and Lawler was always very interesting, then Ludvig Borga destroyed Marty Jannetty, Undertaker took on Giant Gonzalez in another terrible match, The Smoking Gunns and Tatanka took on Bam Bam Bigelow and the Headshrinkers, and Yokozuna defended the world title against Lex Luger this match was boring and it has a terrible ending. However it deserves 8/10\",\n       1], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"from nltk.tokenize import TreebankWordTokenizer\nfrom gensim.models.keyedvectors import KeyedVectors\n\nword_vectors = KeyedVectors.load_word2vec_format('/kaggle/input/googlenewsvectorsnegative300/GoogleNews-vectors-negative300.bin', binary=True, limit=1000)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T05:14:06.270849Z","iopub.execute_input":"2023-04-24T05:14:06.271288Z","iopub.status.idle":"2023-04-24T05:14:07.702632Z","shell.execute_reply.started":"2023-04-24T05:14:06.271253Z","shell.execute_reply":"2023-04-24T05:14:07.701368Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def tokenize_and_vectorize(dataset):\n    tokenizer = TreebankWordTokenizer()\n    vectorized_data = []\n    expected = []\n    for sample in dataset:\n        tokens = tokenizer.tokenize(sample[0])\n        sample_vecs = []\n        for token in tokens:\n            try:\n                sample_vecs.append(word_vectors[token])\n                \n            except KeyError:\n                pass # no matching token in the Google w2v vocab\n            \n        vectorized_data.append(sample_vecs)\n    \n    return vectorized_data","metadata":{"execution":{"iopub.status.busy":"2023-04-24T05:14:09.907589Z","iopub.execute_input":"2023-04-24T05:14:09.908022Z","iopub.status.idle":"2023-04-24T05:14:09.916248Z","shell.execute_reply.started":"2023-04-24T05:14:09.907985Z","shell.execute_reply":"2023-04-24T05:14:09.914782Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def collect_expected(dataset):\n    \"\"\"Peel off the target values from the dataset\"\"\"\n    expected = []\n    for sample in dataset:\n        expected.append(sample[1])\n    return expected","metadata":{"execution":{"iopub.status.busy":"2023-04-24T05:14:11.463712Z","iopub.execute_input":"2023-04-24T05:14:11.464510Z","iopub.status.idle":"2023-04-24T05:14:11.471599Z","shell.execute_reply.started":"2023-04-24T05:14:11.464453Z","shell.execute_reply":"2023-04-24T05:14:11.470256Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#pass data into the functions\nvectorized_data = tokenize_and_vectorize(dataset)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T05:14:12.944487Z","iopub.execute_input":"2023-04-24T05:14:12.944948Z","iopub.status.idle":"2023-04-24T05:14:19.536090Z","shell.execute_reply.started":"2023-04-24T05:14:12.944910Z","shell.execute_reply":"2023-04-24T05:14:19.534623Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"expected = collect_expected(dataset)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T05:14:22.690121Z","iopub.execute_input":"2023-04-24T05:14:22.690608Z","iopub.status.idle":"2023-04-24T05:14:22.698835Z","shell.execute_reply.started":"2023-04-24T05:14:22.690564Z","shell.execute_reply":"2023-04-24T05:14:22.696823Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#train/test split\nsplit_point = int(len(vectorized_data)*.8)\n\nx_train = vectorized_data[:split_point]\ny_train = expected[:split_point]\n\nx_test = vectorized_data[split_point:]\ny_test = expected[split_point:]","metadata":{"execution":{"iopub.status.busy":"2023-04-24T05:14:29.579570Z","iopub.execute_input":"2023-04-24T05:14:29.580014Z","iopub.status.idle":"2023-04-24T05:14:29.588101Z","shell.execute_reply.started":"2023-04-24T05:14:29.579977Z","shell.execute_reply":"2023-04-24T05:14:29.586447Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#truncate any review longer than 400 tokens\n#pad the shorted smaples out to 400 tokens with null or 0\n\nmaxlen = 400\nbatch_size = 32\nembedding_dims = 300\nfilters = 250\nkernel_size = 3\nhidden_dims = 250\nepochs = 2\n\ndef pad_trunc(data, maxlen):\n    \"\"\"\n    for a given dataset pad with zero vectors or truncate to maxlen\n    \"\"\"\n    new_data = []\n    \n    #create a vector of 0s the length of our word vectors\n    zero_vector = []\n    for _ in range(len(data[0][0])):\n        zero_vector.append(0.0)\n        \n    for sample in data:\n        if len(sample) > maxlen:\n            temp = sample[:maxlen]\n        elif len(sample) < maxlen:\n            temp = sample\n            #append the appropriate number 0 vectors to the list\n            additional_elems = maxlen - len(sample)\n            for _ in range(additional_elems):\n                temp.append(zero_vector)         \n        else:\n            temp = sample\n        new_data.append(temp)\n    return new_data","metadata":{"execution":{"iopub.status.busy":"2023-04-24T05:14:32.594021Z","iopub.execute_input":"2023-04-24T05:14:32.594469Z","iopub.status.idle":"2023-04-24T05:14:32.620925Z","shell.execute_reply.started":"2023-04-24T05:14:32.594432Z","shell.execute_reply":"2023-04-24T05:14:32.619449Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#pass the train and test data to padder/truncator\nx_train = pad_trunc(x_train, maxlen)\nx_test = pad_trunc(x_test, maxlen)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T05:14:41.574019Z","iopub.execute_input":"2023-04-24T05:14:41.574455Z","iopub.status.idle":"2023-04-24T05:14:41.731801Z","shell.execute_reply.started":"2023-04-24T05:14:41.574419Z","shell.execute_reply":"2023-04-24T05:14:41.730607Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"x_train = np.reshape(x_train, (len(x_train), maxlen, embedding_dims))\ny_train = np.array(y_train)\n\nx_test = np.reshape(x_test, (len(x_test), maxlen, embedding_dims))\ny_test = np.array(y_test)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T05:14:42.876006Z","iopub.execute_input":"2023-04-24T05:14:42.876468Z","iopub.status.idle":"2023-04-24T05:15:15.619517Z","shell.execute_reply.started":"2023-04-24T05:14:42.876426Z","shell.execute_reply":"2023-04-24T05:15:15.617993Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"num_neurons = 50\nmodel = Sequential()\nmodel.add(LSTM(num_neurons, return_sequences=True, input_shape=(maxlen, embedding_dims)))\nmodel.add(Dropout(.2))\nmodel.add(Flatten())\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile('rmsprop', 'binary_crossentropy', metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-24T05:21:23.923746Z","iopub.execute_input":"2023-04-24T05:21:23.925093Z","iopub.status.idle":"2023-04-24T05:21:24.437658Z","shell.execute_reply.started":"2023-04-24T05:21:23.925031Z","shell.execute_reply":"2023-04-24T05:21:24.436183Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n lstm (LSTM)                 (None, 400, 50)           70200     \n                                                                 \n dropout (Dropout)           (None, 400, 50)           0         \n                                                                 \n flatten (Flatten)           (None, 20000)             0         \n                                                                 \n dense (Dense)               (None, 1)                 20001     \n                                                                 \n=================================================================\nTotal params: 90,201\nTrainable params: 90,201\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"#fit model\nmodel.fit(x_train, y_train,\n         batch_size = batch_size,\n         epochs=epochs,\n         validation_data=(x_test, y_test))\n","metadata":{"execution":{"iopub.status.busy":"2023-04-24T05:33:42.901494Z","iopub.execute_input":"2023-04-24T05:33:42.901940Z","iopub.status.idle":"2023-04-24T05:34:45.651319Z","shell.execute_reply.started":"2023-04-24T05:33:42.901904Z","shell.execute_reply":"2023-04-24T05:34:45.650218Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Epoch 1/2\n125/125 [==============================] - 30s 240ms/step - loss: 0.0524 - accuracy: 0.9850 - val_loss: 1.3702 - val_accuracy: 0.6780\nEpoch 2/2\n125/125 [==============================] - 30s 237ms/step - loss: 0.0499 - accuracy: 0.9860 - val_loss: 1.3552 - val_accuracy: 0.6680\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x790784d0da50>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Scores not impressive because of the dataset size, i only trained the model on around 4000 samples","metadata":{}},{"cell_type":"code","source":"#use the model to predict on a sample\nsample_1 = \"\"\"I hate that the dismal weather had me down for so long, when will it break! Ugh, when does happiness return? The sun is blinding and the puffy clouds are too thin. I can't wait for the weekend.\"\"\"\nvec_list = tokenize_and_vectorize([(sample_1, 1)])\ntest_vec_list = pad_trunc(vec_list, maxlen)\ntest_vec = np.reshape(test_vec_list, (len(test_vec_list), maxlen, embedding_dims))","metadata":{"execution":{"iopub.status.busy":"2023-04-24T05:43:43.449777Z","iopub.execute_input":"2023-04-24T05:43:43.450199Z","iopub.status.idle":"2023-04-24T05:43:43.466695Z","shell.execute_reply.started":"2023-04-24T05:43:43.450164Z","shell.execute_reply":"2023-04-24T05:43:43.465483Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"print(f\"Sample's sentiment, 1- pos, 0- neg: {model.predict(test_vec)}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-24T05:44:18.249579Z","iopub.execute_input":"2023-04-24T05:44:18.251012Z","iopub.status.idle":"2023-04-24T05:44:18.364573Z","shell.execute_reply.started":"2023-04-24T05:44:18.250963Z","shell.execute_reply":"2023-04-24T05:44:18.362447Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 57ms/step\nSample's sentiment, 1- pos, 0- neg: [[0.04737292]]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}