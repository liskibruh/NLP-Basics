{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e6d6f6b-4d0a-4397-81d6-950cba256879",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is just a sample code for building a CNNClassifier in PyTorch\n",
    "It is not using any atual data for training\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "    \n",
    "def calc_conv_out_seq_len(seq_len, kernel_len, stride=1, dilation=1, padding=0):\n",
    "    return (\n",
    "        1 + (seq_len + 2 * padding - dilation * (kernel_len - 1) - 1) //stride\n",
    "        )\n",
    "\n",
    "\n",
    "class CNNTextClassifier(nn.Module):\n",
    "    def __init__(self, embeddings):\n",
    "        super().__init__()\n",
    "\n",
    "        self.seq_len = 40\n",
    "        self.vocab_size = 10000\n",
    "        self.embedding_size = 50\n",
    "        self.out_channels = 5\n",
    "        self.kernel_lenghts = [2,3,4,5,6]\n",
    "        self.strid = 1\n",
    "        self.dropout = nn.Droput(0)\n",
    "        self.pool_strid = self.strid\n",
    "        self.conv_out_seq_len = calc_out_seq_len(\n",
    "                                        self_len=self.seq_len,\n",
    "                                        kernel_lengths=self.kernel_lengths,\n",
    "                                        strid=self.stride\n",
    "                                        )\n",
    "\n",
    "        self.embed = nn.Embedding(\n",
    "            self.vocab_size,\n",
    "            self.embdedding_size,\n",
    "            padding_idx=0)\n",
    "        state = self.embed.state_dict()\n",
    "        state['weight'] = embeddings\n",
    "        self.embed.load_state_dict(state)\n",
    "\n",
    "        self.convolvers = []\n",
    "        self.poolers = []\n",
    "        total_out_len = 0\n",
    "\n",
    "        for i, kernel_len in enumerate(self.kernel_lengths):\n",
    "            self.convolvers.append(\n",
    "                nn.Conv1d(in_channels=self.embedding_size,\n",
    "                          out_channels=self.out_channels,\n",
    "                          kernel_size=kernel_len,\n",
    "                          stride=self.stride)\n",
    "                )\n",
    "\n",
    "            print(f'conv[{i}].weight.shape: {self.convolvers[-1].weight.shape}') \n",
    "            conv_output_len = calc_conv_out_seq_len(seq_len=self.seq_len, kernel_len=kernel_len, stride=self.stride)\n",
    "            print(f'conv_output_len: {conv_output_len}')\n",
    "\n",
    "            self.poolers.append(\n",
    "                nn.MaxPool1d(kernel_size=conv_output_len, \n",
    "                             stride=self.stride)\n",
    "                )\n",
    "            total_out_len += calc_conv_out_seq_len( seq_len=conv_output_len, kernel_len=conv_output_len, stride=self.stride)\n",
    "            print(f'total_out_len: {total_out_len}')\n",
    "            print(f'poolers[{i}]: {self.poolers[-1]}')\n",
    "\n",
    "\n",
    "        print(f'total_out_len: {total_out_len}') \n",
    "        self.linear_layer = nn.Linear(self.out_channels * total_out_len, 1)\n",
    "        print(f'linear_layer: {self.linear_layer}')\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embed(x).permute(0, 2, 1)  # Embedding layer + permutation for Conv1d\n",
    "        pooled_outputs = []\n",
    "\n",
    "        for convolver, pooler in zip(self.convolvers, self.poolers):\n",
    "            conv_output = convolver(embedded)\n",
    "            pooled_output = pooler(conv_output)\n",
    "            pooled_outputs.append(pooled_output)\n",
    "\n",
    "        combined_output = torch.cat(pooled_outputs, dim=1)  # Concatenate pooled outputs along channel dimension\n",
    "        flattened_output = combined_output.view(-1, self.linear_input_size)  # Flatten the pooled outputs\n",
    "        final_output = self.linear_layer(flattened_output)  # Linear layer\n",
    "\n",
    "        return torch.sigmoid(final_output)  # Sigmoid activation for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21db411d-57f1-4fbe-90d2-6e1c89d8865f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the model\n",
    "model = CNNTextClassifier(embeddings)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()  # Binary cross-entropy loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for inputs, labels in train_loader:  # Iterate over batches of training data\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, labels.float())  # Calculate the loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update the parameters\n",
    "\n",
    "    # Validation loop (optional)\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_labels in val_loader:  # Iterate over batches of validation data\n",
    "            val_outputs = model(val_inputs)  # Forward pass\n",
    "            val_loss = criterion(val_outputs, val_labels.float())  # Calculate the loss\n",
    "\n",
    "    # Print training and validation metrics (optional)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
