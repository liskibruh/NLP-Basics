{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37926d8f-adbd-4032-82bb-64b81c3827ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" \n",
      " = 2013 – 14 York City F.C. season = \n",
      " \n",
      " The 2013 – 14 season was the <unk> season of competitive association football and 77th season in the Football League played by York City Football Club , a professional football club based in York , North Yorkshire , England . Their 17th @-@ place finish in 2012 – 13 meant it was their second consecutive season in League Two . The season ran from 1 July 2013 to 30 June 2014 . \n",
      " Nigel Worthington , starting his first full season as York manager , made eight permanent summer signings . By the turn of the year York were only above the relegation zone on goal difference , before a 17 @-@ match unbeaten run saw the team finish in seventh @-@ place in the 24 @-@ team 2013 – 14 Football League Two . This meant York qualified for the play @-@ offs , and they were eliminated in the semi @-@ final by Fleetwood Town . York were knocked out of the 2013 – 14 FA Cup , Football League Cup and Football League Trophy in their opening round matches . \n",
      " 35 playe\n"
     ]
    }
   ],
   "source": [
    "filepath = \"torchtext/WikiText2-10000.txt\"\n",
    "\n",
    "with open(filepath, 'r', encoding='utf-8') as file:\n",
    "    text_content = file.read()\n",
    "\n",
    "print(text_content[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d455b8b-0c6a-49cc-a3ae-7d095907c435",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oo_wa\\.conda\\envs\\nlpia_new\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 37333\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "dset = datasets.load_dataset('text', data_files=str(filepath))\n",
    "dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fb03cfe-c2ba-4291-9cc5-cb314144dca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\" ',\n",
       " ' = 2013 – 14 York City F.C. season = ',\n",
       " ' ',\n",
       " ' The 2013 – 14 season was the <unk> season of competitive association football and 77th season in the Football League played by York City Football Club , a professional football club based in York , North Yorkshire , England . Their 17th @-@ place finish in 2012 – 13 meant it was their second consecutive season in League Two . The season ran from 1 July 2013 to 30 June 2014 . ']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset['train']['text'][0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "868cca3a-5724-41d0-9b50-5379c3bdbe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_row(row):\n",
    "    row['tokens'] = row['text'].lower().split()\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41c586c3-7cff-4631-a951-7203c4d5516f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'tokens'],\n",
       "        num_rows: 37333\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset = dset.map(tokenize_row)\n",
    "dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f94a373-863d-4857-93be-d00ba1ed759c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['\"'], ['=', '2013', '–', '14', 'york', 'city', 'f.c.', 'season', '=']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset['train']['tokens'][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bab8566e-349a-43c9-b6ba-0169ab6b78ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['relieve', 'hottest', 'hypnotic', 'rusty']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = list(set(\n",
    "    [tok for row in dset['train']['tokens'] for tok in row]))\n",
    "\n",
    "vocab[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adc6c186-3177-4b65-83b5-ee73c52e816a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'relieve'), (1, 'hottest'), (2, 'hypnotic'), (3, 'rusty')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2tok = dict(enumerate(vocab))\n",
    "list(id2tok.items())[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d983ea7f-5733-4b30-8b30-a29fc5d076d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('relieve', 0), ('hottest', 1), ('hypnotic', 2), ('rusty', 3)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok2id = {tok: i for (i,tok) in id2tok.items()}\n",
    "list(tok2id.items())[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2665547-6300-453b-9783-50ba23f1c3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_width = 10\n",
    "\n",
    "def windowizer(row, wsize=window_width):\n",
    "    \"\"\" Compute sentence (str) to sliding-window of skip-gram pairs \"\"\"\n",
    "    doc = row['tokens']\n",
    "    out = []\n",
    "    for i, wd in enumerate(doc):\n",
    "        target = tok2id[wd]\n",
    "        window = [\n",
    "            i+j for j in range(-wsize, wsize+1, 1)\n",
    "            if (i+j >=0) & (i+j < len(doc)) & (j != 0)\n",
    "        ]\n",
    "\n",
    "        out += [(target, tok2id[doc[w]]) for w in window]\n",
    "    row['window'] = out\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d13bd4ce-1c5b-4221-93ec-f588489dc63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████████████████████████████████████| 37333/37333 [01:47<00:00, 347.81 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'tokens', 'window'],\n",
       "        num_rows: 37333\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset = dset.map(windowizer)\n",
    "dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e00c9e25-044d-45c0-bdb2-ba2ed4503dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[8506, 4935],\n",
       " [8506, 28203],\n",
       " [8506, 4530],\n",
       " [8506, 27734],\n",
       " [8506, 14724],\n",
       " [8506, 13791],\n",
       " [8506, 26745],\n",
       " [8506, 8506],\n",
       " [4935, 8506],\n",
       " [4935, 28203],\n",
       " [4935, 4530],\n",
       " [4935, 27734],\n",
       " [4935, 14724],\n",
       " [4935, 13791],\n",
       " [4935, 26745],\n",
       " [4935, 8506],\n",
       " [28203, 8506],\n",
       " [28203, 4935],\n",
       " [28203, 4530],\n",
       " [28203, 27734],\n",
       " [28203, 14724],\n",
       " [28203, 13791],\n",
       " [28203, 26745],\n",
       " [28203, 8506],\n",
       " [4530, 8506],\n",
       " [4530, 4935],\n",
       " [4530, 28203],\n",
       " [4530, 27734],\n",
       " [4530, 14724],\n",
       " [4530, 13791],\n",
       " [4530, 26745],\n",
       " [4530, 8506],\n",
       " [27734, 8506],\n",
       " [27734, 4935],\n",
       " [27734, 28203],\n",
       " [27734, 4530],\n",
       " [27734, 14724],\n",
       " [27734, 13791],\n",
       " [27734, 26745],\n",
       " [27734, 8506],\n",
       " [14724, 8506],\n",
       " [14724, 4935],\n",
       " [14724, 28203],\n",
       " [14724, 4530],\n",
       " [14724, 27734],\n",
       " [14724, 13791],\n",
       " [14724, 26745],\n",
       " [14724, 8506],\n",
       " [13791, 8506],\n",
       " [13791, 4935],\n",
       " [13791, 28203],\n",
       " [13791, 4530],\n",
       " [13791, 27734],\n",
       " [13791, 14724],\n",
       " [13791, 26745],\n",
       " [13791, 8506],\n",
       " [26745, 8506],\n",
       " [26745, 4935],\n",
       " [26745, 28203],\n",
       " [26745, 4530],\n",
       " [26745, 27734],\n",
       " [26745, 14724],\n",
       " [26745, 13791],\n",
       " [26745, 8506],\n",
       " [8506, 8506],\n",
       " [8506, 4935],\n",
       " [8506, 28203],\n",
       " [8506, 4530],\n",
       " [8506, 27734],\n",
       " [8506, 14724],\n",
       " [8506, 13791],\n",
       " [8506, 26745]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset['train']['window'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdca9b41-0226-4d1a-82f0-007fdf91b590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skip_grams(tokens, window_width=window_width):\n",
    "    pairs = []\n",
    "    for i, wd in enumerate(tokens):\n",
    "        target = toke2id[wd]\n",
    "        window = [\n",
    "            i+j for j in\n",
    "            range(-window_width, window_width+1, 1)\n",
    "            if(i+j >= 0)\n",
    "            & (i+j < len(tokens))\n",
    "            & (j != 0)\n",
    "        ]\n",
    "\n",
    "        pairs.extend([(target, tok2id[tokens[w]]) for w in window])\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18dd036f-f049-40d1-9993-28e53cbd8d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Word2VecDataset(Dataset):\n",
    "    def __init__(self, dataset, vocab_size, wsize=window_width):\n",
    "        self.dataset = dataset\n",
    "        self.vocab_size = vocab_size\n",
    "        self.data = [i for s in dataset['window'] for i in s]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5eb98e18-815e-4f48-96d1-bce7d36c034e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "CPU_CORES = 4\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "dataloader = {}\n",
    "for k in dset.keys():\n",
    "    dataloader = {\n",
    "        k: DataLoader(\n",
    "            Word2VecDataset(\n",
    "                dset[k],\n",
    "                vocab_size=len(vocab)),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            num_workers = CPU_CORES -1)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "316d30ca-03e6-4668-b931-faaa45a96d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(input_id, size):\n",
    "    vec = torch.zeros(size).float()\n",
    "    vec[input_id]=1.0\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0062aeed-1ef4-4976-9aef-f7f5482b8242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "EMBED_DIM = 100\n",
    "\n",
    "class Word2Vec(nn.Module):\n",
    "    def __init__(self, vocab_size=len(vocab), embedding_size=EMBED_DIM):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.expand = nn.Linear(embedding_size, vocab_size, bias=False)\n",
    "\n",
    "    def forward(self, input):\n",
    "        hidden = self.embed(input)\n",
    "        logits = self.expand(hidden)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6c0ef0c-5ff4-423c-88b9-6d8258e47dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word2Vec(\n",
       "  (embed): Embedding(28912, 100)\n",
       "  (expand): Linear(in_features=100, out_features=28912, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f54bc56-b44b-4c24-9e6d-8213ab76db6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "497d1474-0954-4198-aaf4-e177635edf91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word2Vec(\n",
       "  (embed): Embedding(28912, 100)\n",
       "  (expand): Linear(in_features=100, out_features=28912, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1b66ac-6ed0-49cd-8dd0-bcd7ddf635dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 5e-4\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "running_loss = [] \n",
    "pbar = tqdm(range(EPOCHS * len(dataloader['train']))) \n",
    "\n",
    "for epoch in range(EPOCHS): \n",
    "    epoch_loss = 0 \n",
    "    for sample_num, (center, context) in enumerate(dataloader['train']): \n",
    "        if sample_num % len(dataloader['train']) == 2: \n",
    "            print(center, context) \n",
    "            # center: tensor([ 229,0, 2379, ..., 402, 553, 521]) \n",
    "            # context: tensor([ 112, 1734, 802, ..., 28, 852, 363])\n",
    "        center, context = center.to(device), context.to(device) \n",
    "        optimizer.zero_grad() \n",
    "        logits = model(input=context) \n",
    "        loss = loss_fn(logits, center) \n",
    "        if not sample_num % 10000: \n",
    "            # print(center, context) \n",
    "            pbar.set_description(f'loss[{sample_num}] = {loss.item()}')\n",
    "        epoch_loss += loss.item() \n",
    "        loss.backward() \n",
    "        optimizer.step() \n",
    "        pbar.update(1)\n",
    "    epoch_loss /= len(dataloader['train']) \n",
    "    running_loss.append(epoch_loss)\n",
    "\n",
    "save_model(model, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d80f91-4e94-4edb-b98a-fa3458e2770c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
