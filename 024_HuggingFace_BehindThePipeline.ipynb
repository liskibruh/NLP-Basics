{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPB35ukJWzmgmX7iuTQXWzJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"1mNTIowLcB9G","executionInfo":{"status":"ok","timestamp":1682662082550,"user_tz":-300,"elapsed":15398,"user":{"displayName":"Bizoo Bizoo","userId":"08505249684389076845"}},"outputId":"62ef287b-c2d2-4001-b3ac-7a4cb2ab8cd6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"]}],"source":["!pip install transformers"]},{"cell_type":"markdown","source":["## Tokenizer"],"metadata":{"id":"y1G9-kTCfRW5"}},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","\n","checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)"],"metadata":{"id":"L1YZFvp1eJyN","executionInfo":{"status":"ok","timestamp":1682662916811,"user_tz":-300,"elapsed":459,"user":{"displayName":"Bizoo Bizoo","userId":"08505249684389076845"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["raw_inputs = (['This food is really good.', \"I don't like how it tastes.\"])\n","inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors='tf')\n","print(inputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"scJYo4e6en2W","executionInfo":{"status":"ok","timestamp":1682662966610,"user_tz":-300,"elapsed":834,"user":{"displayName":"Bizoo Bizoo","userId":"08505249684389076845"}},"outputId":"fdde88b5-c95d-432f-99d2-cbea3fc85ab0"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["{'input_ids': <tf.Tensor: shape=(2, 11), dtype=int32, numpy=\n","array([[  101,  2023,  2833,  2003,  2428,  2204,  1012,   102,     0,\n","            0,     0],\n","       [  101,  1045,  2123,  1005,  1056,  2066,  2129,  2009, 16958,\n","         1012,   102]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(2, 11), dtype=int32, numpy=\n","array([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n","       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>}\n"]}]},{"cell_type":"markdown","source":["## Model"],"metadata":{"id":"i17alFgAfTfM"}},{"cell_type":"code","source":["from transformers import TFAutoModelForSequenceClassification\n","\n","checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n","model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ar93PftvfEaO","executionInfo":{"status":"ok","timestamp":1682662972896,"user_tz":-300,"elapsed":4894,"user":{"displayName":"Bizoo Bizoo","userId":"08505249684389076845"}},"outputId":"caf8117b-10a6-4ea5-b34a-9f141f39d207"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english and are newly initialized: ['dropout_197']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"markdown","source":["## Output"],"metadata":{"id":"c5sn--07fqmB"}},{"cell_type":"code","source":["outputs = model(inputs)\n","print(outputs.logits.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TwrsiXF4fj9I","executionInfo":{"status":"ok","timestamp":1682662977184,"user_tz":-300,"elapsed":607,"user":{"displayName":"Bizoo Bizoo","userId":"08505249684389076845"}},"outputId":"ffbc4c4a-d333-4e49-e4e5-0b8a3697af52"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["(2, 2)\n"]}]},{"cell_type":"markdown","source":["## Postprocessing the output"],"metadata":{"id":"p9iXfnqPgMq4"}},{"cell_type":"code","source":["print(outputs.logits)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ckvJmb0wfznF","executionInfo":{"status":"ok","timestamp":1682662979382,"user_tz":-300,"elapsed":6,"user":{"displayName":"Bizoo Bizoo","userId":"08505249684389076845"}},"outputId":"fb250ece-4a4d-4d01-8bbe-87d175bb3488"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[-4.2772193  4.6635175]\n"," [ 3.4940817 -2.8776333]], shape=(2, 2), dtype=float32)\n"]}]},{"cell_type":"markdown","source":["Those are not probabilities but logits, the raw, unnormalized scores outputted by the last layer of the model. To be converted to probabilities, they need to go through a SoftMax layer (all ü§ó Transformers models output the logits, as the loss function for training will generally fuse the last activation function, such as SoftMax, with the actual loss function, such as cross entropy):"],"metadata":{"id":"X8fy9SAChIGb"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","predictions = tf.math.softmax(outputs.logits, axis=-1)\n","print(predictions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_0_OO8pDg-9r","executionInfo":{"status":"ok","timestamp":1682662981643,"user_tz":-300,"elapsed":4,"user":{"displayName":"Bizoo Bizoo","userId":"08505249684389076845"}},"outputId":"55d447a7-abc1-42a8-a8df-34e37c1dc2ec"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[1.3092738e-04 9.9986911e-01]\n"," [9.9829370e-01 1.7063088e-03]], shape=(2, 2), dtype=float32)\n"]}]},{"cell_type":"markdown","source":["To get the labels corresponding to each position, we can inspect the id2label attribute of the model config "],"metadata":{"id":"Y6CkvvpihRK3"}},{"cell_type":"code","source":["model.config.id2label"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Om-SR7XYhK67","executionInfo":{"status":"ok","timestamp":1682662985656,"user_tz":-300,"elapsed":6,"user":{"displayName":"Bizoo Bizoo","userId":"08505249684389076845"}},"outputId":"c87f524a-7a6a-45ba-d8e3-944d169e372e"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: 'NEGATIVE', 1: 'POSITIVE'}"]},"metadata":{},"execution_count":31}]}]}